{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haberman Breast Cancer Classification\n",
    "\n",
    "In this project, i will use a small breast cancer survival dataset, referred to generally as the\n",
    "Haberman Dataset. The dataset describes breast cancer patient data and the outcome is patient\n",
    "survival. Specifically whether the patient survived for five years or longer, or whether the\n",
    "patient did not survive. This is a standard dataset used in the study of imbalanced classification.\n",
    "According to the dataset description, the breast cancer surgery operations were conducted\n",
    "between 1958 and 1970 at the University of Chicago’s Billings Hospital. There are 306 examples\n",
    "in the dataset, and there are 3 input variables; they are:\n",
    "- The age of the patient at the time of the operation.\n",
    "- The two-digit year of the operation.\n",
    "- The number of positive axillary nodes detected, a measure of a cancer has spread.\n",
    "As such, i have no control over the selection of cases that make up the dataset or features\n",
    "to use in those cases, other than what is available in the dataset. Although the dataset describes\n",
    "breast cancer patient survival, given the small dataset size and the fact the data is based on\n",
    "breast cancer diagnosis and operations many decades ago, any models built on this dataset are\n",
    "not expected to generalize.\n",
    "To be crystal clear, I am  not solving breast cancer. I am exploring a standard imbalanced\n",
    "classification dataset. i choose to frame this dataset as the prediction of a probability of\n",
    "patient survival. That is: Given patient breast cancer surgery details, what is the probability of\n",
    "survival of the patient to five years or more?\n",
    "This will provide the basis for exploring probabilistic algorithms that can predict a probability\n",
    "instead of a class label and metrics for evaluating models that predict probabilities instead of\n",
    "class labels. Next, let’s take a closer look at the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare probabilistic model on the haberman dataset\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>nodes</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  year  nodes  class\n",
       "0   30    64      1      1\n",
       "1   30    62      3      1\n",
       "2   30    65      0      1\n",
       "3   31    59      2      1\n",
       "4   31    65      4      1\n",
       "5   33    58     10      1\n",
       "6   33    60      0      1\n",
       "7   34    59      0      2\n",
       "8   34    66      9      2\n",
       "9   34    58     30      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "filepath = \"E:\\IMBALANCE ANALYSIS\\haberman.csv\"\n",
    "columns = ['age', 'year', 'nodes', 'class'] # Given the columns name\n",
    "data = pd.read_csv(filepath, header=None, names=columns)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calling the describe() function to create a summary of each column and print\n",
    "the contents of the report. A summary for a column includes useful details like the min and\n",
    "max values, the mean and standard deviation of which are useful if the variable has a Gaussian\n",
    "distribution, and the 25th, 50th, and 75th quartiles, which are useful if the variable does not\n",
    "have a Gaussian distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count       mean        std   min   25%   50%    75%   max\n",
      "age    306.0  52.457516  10.803452  30.0  44.0  52.0  60.75  83.0\n",
      "year   306.0  62.852941   3.249405  58.0  60.0  63.0  65.75  69.0\n",
      "nodes  306.0   4.026144   7.189654   0.0   0.0   1.0   4.00  52.0\n",
      "class  306.0   1.264706   0.441899   1.0   1.0   1.0   2.00   2.0\n"
     ]
    }
   ],
   "source": [
    "# summarize each column\n",
    "\n",
    "reports = data.describe()\n",
    "print(reports.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the age, I can see that the youngest patient was\n",
    "30 and the oldest was 83; that is quite a range. The mean patient age was about 52 years. If the\n",
    "occurrence of cancer is somewhat random, we might expect the age distribution to be Gaussian.\n",
    "I can see that all operations were performed between 1958 and 1969. If the number of\n",
    "breast cancer patients is somewhat fixed over time, we might expect this variable to have a\n",
    "uniform distribution. We can see nodes have values between 0 and 52. This might be a cancer\n",
    "diagnostic related to lymphatic nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables are integers. Therefore, it might be helpful to look at each variable as a\n",
    "histogram to get an idea of the variable distribution. This might be helpful in case we choose\n",
    "models later that are sensitive to the data distribution or scale of the data, in which case, I\n",
    "might need to transform or rescale the data. We can create a histogram of each variable in the\n",
    "DataFrame by calling the hist() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a histogram plot of each variable\n",
    "data.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a histogram for each variable. i can see that age appears\n",
    "to have a Gaussian distribution, as we might have expected.I can also see that year has\n",
    "a uniform distribution, mostly, with an outlier in the first year showing nearly double the\n",
    "number of operations. We can see nodes has an exponential type distribution with perhaps most\n",
    "examples showing 0 nodes, with a long tail of values after that. A transform to un-bunch this\n",
    "distribution might help some models later on. Finally, we can see the two-class values with an\n",
    "unequal class distribution, showing perhaps 2- or 3-times more survival than non-survival cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=1, Count=225, Percentage=73.529%\n",
      "Class=2, Count=81, Percentage=26.471%\n"
     ]
    }
   ],
   "source": [
    "# It may be helpful to know how imbalanced the dataset actually is. I can use the Counter\n",
    "# object to count the number of examples in each class, then use those counts to summarize the distribution\n",
    "\n",
    "# summarize the class distribution\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "target = data['class'].values\n",
    "counter = Counter(target)\n",
    "for k, v in counter.items():\n",
    "    per = v / len(target) * 100\n",
    "    print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example summarizes the class distribution for the dataset. I can see that\n",
    "class 1 for survival has the most examples at 225, or about 74 percent of the dataset. I can\n",
    "see class 2 for non-survival has fewer examples at 81, or about 26 percent of the dataset. The\n",
    "class distribution is skewed, but it is not severely imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model and test harness for the haberman dataset\n",
    "from collections import Counter\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Test and Baseline Result\n",
    "I will evaluate candidate models using repeated stratified k-fold cross-validation. The k-fold\n",
    "cross-validation procedure provides a good general estimate of model performance that is not\n",
    "too optimistically biased, at least compared to a single train-test split. We will use k = 10,\n",
    "meaning each fold will contain 306\n",
    "10 or about 30 examples.\n",
    "Stratified means that each fold will contain the same mixture of examples by class, that is\n",
    "about 74 percent to 26 percent survival and non-survival. Repeated means that the evaluation\n",
    "process will be performed multiple times to help avoid fluke results and better capture the\n",
    "variance of the chosen model. We will use three repeats. This means a single model will be\n",
    "fit and evaluated 10 × 3 (30) times and the mean and standard deviation of these runs will be\n",
    "reported. This can be achieved using the RepeatedStratifiedKFold scikit-learn class.\n",
    "Given that we are interested in predicting a probability of survival, I need a performance\n",
    "metric that evaluates the skill of a model based on the predicted probabilities. In this case,\n",
    "I will use the Brier score that calculates the mean squared error between the predicted\n",
    "probabilities and the expected probabilities. This\n",
    "can be calculated using the brier score loss() scikit-learn function. This score is minimized,\n",
    "with a perfect score of 0.0. We can invert the score to be maximizing by comparing a predicted\n",
    "score to a reference score, showing how much better the model is compared to the reference\n",
    "between 0.0 for the same, to 1.0 with perfect skill. Any models that achieve a score less than\n",
    "0.0 represents less skill than the reference model. This is called the Brier Skill Score, or BSS for\n",
    "short.\n",
    "It is customary for an imbalanced dataset to model the minority class as a positive class. In\n",
    "this dataset, the positive class represents non-survival. This means that we will be predicting\n",
    "the probability of non-survival and will need to calculate the complement of the predicted\n",
    "probability in order to get the probability of survival. As such, we can map the 1 class values\n",
    "(survival) to the negative case with a 0 class label, and the 2 class values (non-survival) to the\n",
    "positive case with a class label of 1. This can be achieved using the LabelEncoder class. For\n",
    "example, the load dataset() function below will load the dataset, split the variable columns\n",
    "into input and outputs, and then encode the target variable to 0 and 1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset(full_path):\n",
    "    # load the dataset as a numpy array\n",
    "    data = read_csv(full_path, header=None)\n",
    "    # retrieve numpy array\n",
    "    data = data.values\n",
    "\n",
    "    #split into input and output elements\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "\n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, i can calculate the Brier skill score for a model. First, i need a Brier score for a\n",
    "reference prediction. A reference prediction for a problem in which i am  predicting probabilities\n",
    "is the probability of the positive class label in the dataset. In this case, the positive class\n",
    "label represents non-survival and occurs about 26% in the dataset. Therefore, predicting about\n",
    "0.26471 represents the worst-case or baseline performance for a predictive model on this dataset.\n",
    "Any model that has a Brier score better than this has some skill, where as any model that\n",
    "as a Brier score lower than this has no skill. The Brier Skill Score captures this important\n",
    "relationship. We can calculate the Brier score for this default prediction strategy automatically\n",
    "for each training set in the k-fold cross-validation process, then use it as a point of comparison\n",
    "for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate reference brier score\n",
    "ref_probs = [0.26471 for _ in range(len(y))]\n",
    "bs_ref = brier_score_loss(y, ref_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate brier skill score (BSS)\n",
    "def brier_skill_score(y_true, y_prob):\n",
    "\n",
    "    # calculate reference brier score\n",
    "    ref_probs = [0.26471 for _ in range(len(y_true))]\n",
    "    bs_ref = brier_score_loss(y_true, ref_probs)\n",
    "\n",
    "    # calculate model brier score\n",
    "    bs_model = brier_score_loss(y_true, y_prob)\n",
    "    \n",
    "    # calculate skill score\n",
    "    return 1.0 - (bs_model / bs_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, i can make use of the brier skill score() function to evaluate a model using\n",
    "repeated stratified k-fold cross-validation. To use our custom performance metric, i can\n",
    "use the make scorer() scikit-learn function that takes the name of our custom function and\n",
    "creates a metric that i can use to evaluate models with the scikit-learn API. i will set the\n",
    "needs proba argument to True to ensure that models that are evaluated make predictions using\n",
    "the predict proba() function to ensure they give probabilities instead of class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # define the model evaluation metric\n",
    "    metric = make_scorer(brier_skill_score, needs_proba=True)\n",
    "    \n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluate model() function below defines the evaluation procedure with our custom\n",
    "evaluation metric, taking the entire training dataset and model as input, then returns the sample\n",
    "of scores across each fold and each repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 3) (306,) Counter({0: 225, 1: 81})\n",
      "Mean BSS: -0.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# define the location of the dataset\n",
    "full_path = \"E:\\IMBALANCE ANALYSIS\\haberman.csv\"\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset(full_path)\n",
    "\n",
    "# summarize the loaded dataset\n",
    "print(X.shape, y.shape, Counter(y))\n",
    "\n",
    "# define the reference model\n",
    "model = DummyClassifier(strategy='prior')\n",
    "\n",
    "# In this case, i will be evaluate the baseline strategy of predicting the distribution of positive\n",
    "# examples in the training set as the probability of each case in the test set. This can be\n",
    "# implemented automatically using the DummyClassifier class and setting the strategy to\n",
    "# ‘prior’ that will predict the prior probability of each class in the training dataset, which for\n",
    "# the positive class we know is about 0.26471\n",
    "\n",
    "# evaluate the model\n",
    "scores = evaluate_model(X, y, model)\n",
    "\n",
    "# summarize performance\n",
    "print('Mean BSS: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first loads the dataset and reports the number of cases correctly as\n",
    "306 and the distribution of class labels for the negative and positive cases as we expect. The\n",
    "DummyClassifier with  default strategy is then evaluated using repeated stratified k-fold\n",
    "cross-validation and the mean and standard deviation of the Brier Skill Score is reported as 0.0.\n",
    "This is as we expected, as we are using the test harness to evaluate the reference strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Probabilistic Models\n",
    "In this section of the code, i will use the test harness developed in the previous section to evaluate a suite\n",
    "of algorithms and then improvements to those algorithms, such as data preparation schemes.\n",
    "\n",
    "\n",
    "I will evaluate a suite of models that are known to be effective at predicting probabilities.\n",
    "Specifically, these are models that are fit under a probabilistic framework and explicitly predict a\n",
    "calibrated probability for each example. As such, this makes them well-suited to this dataset, even\n",
    "with the class imbalance. I will evaluate the following six probabilistic models implemented\n",
    "with the scikit-learn library:\n",
    "- Logistic Regression (LR)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- Quadratic Discriminant Analysis (QDA)\n",
    "- Gaussian Naive Bayes (GNB)\n",
    "- Multinomial Naive Bayes (MNB)\n",
    "- Gaussian Process (GPC)\n",
    "\n",
    "\n",
    "I am interested in directly comparing the results from each of these algorithms. Each algorithm will be compare based on the mean score, as well as based on their distribution of scores.\n",
    "\n",
    "I define a function to create models that we want to evaluate, each with their default\n",
    "configuration or configured as to not produce a warning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.060 (0.143)\n",
      ">LDA 0.064 (0.154)\n",
      ">QDA 0.027 (0.221)\n",
      ">GNB 0.012 (0.212)\n",
      ">GPC -0.142 (0.041)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "\n",
    "# defining models to test\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "\n",
    "    # LR\n",
    "    models.append(LogisticRegression(solver='lbfgs'))\n",
    "    names.append('LR')\n",
    "\n",
    "    # LDA\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    names.append('LDA')\n",
    "\n",
    "    # QDA\n",
    "    models.append(QuadraticDiscriminantAnalysis())\n",
    "    names.append('QDA')\n",
    "\n",
    "    # GNB\n",
    "    models.append(GaussianNB())\n",
    "    names.append('GNB')\n",
    "\n",
    "    # MNB\n",
    "    #models.append(MultinomialNB())\n",
    "    #names.append('MNB')\n",
    "\n",
    "    # GPC\n",
    "    models.append(GaussianProcessClassifier())\n",
    "    names.append('GPC')\n",
    "    return models, names\n",
    "\n",
    "\n",
    "# define models\n",
    "models, names = get_models()\n",
    "results = list()\n",
    "\n",
    "# evaluate each model\n",
    "for i in range(len(models)):\n",
    "\n",
    "    # evaluate the model and store results\n",
    "    scores = evaluate_model(X, y, models[i])\n",
    "    results.append(scores)\n",
    "\n",
    "    # summarize and store\n",
    "    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))\n",
    "\n",
    "    \n",
    "# plot the results\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results suggest that only two of the algorithms are not skillful, showing\n",
    "negative scores, and that perhaps the LR and LDA algorithms are the best performing.\n",
    "\n",
    "\n",
    "A box and whisker plot was created summarizing the distribution of results. Interestingly,\n",
    "most if not all algorithms show a spread indicating that they may be unskillful on some of the\n",
    "runs. The distribution between the two top-performing models appears roughly equivalent, so\n",
    "choosing a model based on mean performance might be a good start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation With Scaled Inputs\n",
    "It can be a good practice to scale data for some algorithms if the variables have different units\n",
    "of measure, as they do in this case. Algorithms like the LR and LDA are sensitive to the\n",
    "distribution of the data and assume a Gaussian distribution for the input variables, which i\n",
    "don’t have in all cases.\n",
    "\n",
    "Nevertheless, i can test the algorithms with standardization, where each variable is shifted\n",
    "to a zero mean and unit standard deviation. I will drop the MNB algorithm as it does not\n",
    "support negative input values. I can achieve this by wrapping each model in a Pipeline\n",
    "where the first step is a StandardScaler, which will correctly be fit on the training dataset and\n",
    "applied to the test dataset within each k-fold cross-validation evaluation, preventing any data\n",
    "leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.062 (0.140)\n",
      ">LDA 0.064 (0.154)\n",
      ">QDA 0.027 (0.221)\n",
      ">GNB 0.012 (0.212)\n",
      ">GPC 0.097 (0.133)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# define models\n",
    "models, names = get_models()\n",
    "results = list()\n",
    "\n",
    "# evaluate each model\n",
    "for i in range(len(models)):\n",
    "\n",
    "    # create a pipeline\n",
    "    pipeline = Pipeline(steps=[('t', StandardScaler()),('m',models[i])])\n",
    "\n",
    "    # evaluate the model and store results\n",
    "    scores = evaluate_model(X, y, pipeline)\n",
    "    results.append(scores)\n",
    "\n",
    "\n",
    "    # summarize and store\n",
    "    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))\n",
    "\n",
    "\n",
    "# plot the results\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the standardization has not had much of an impact on the\n",
    "algorithms, except the GPC. The performance of the GPC with standardization has shot up\n",
    "and is now the best-performing technique. This highlights the importance of preparing data to\n",
    "meet the expectations of each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation With Power Transform\n",
    "Power transforms, such as the Box-Cox and Yeo-Johnson transforms, are designed to change\n",
    "the distribution to be more Gaussian. This will help with the age input variable in our dataset\n",
    "and may help with the nodes variable and un-bunch the distribution slightly\n",
    "\n",
    "The power transform may make use of a log() function, which does not work on zero\n",
    "values. I have zero values in our dataset, therefore I will scale the dataset prior to the power\n",
    "transform using a MinMaxScaler. Again, I can use this transform in a Pipeline to ensure it\n",
    "is fit on the training dataset and applied to the train and test datasets correctly, without data\n",
    "leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.110 (0.142)\n",
      ">LDA 0.107 (0.164)\n",
      ">GPC 0.100 (0.130)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define models to test\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "\n",
    "    # LR\n",
    "    models.append(LogisticRegression(solver='lbfgs'))\n",
    "    names.append('LR')\n",
    "\n",
    "    # LDA\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    names.append('LDA')\n",
    "\n",
    "    # GPC\n",
    "    models.append(GaussianProcessClassifier())\n",
    "    names.append('GPC')\n",
    "    return models, names\n",
    "\n",
    "\n",
    "\n",
    "# define models\n",
    "models, names = get_models()\n",
    "results = list()\n",
    "# evaluate each model\n",
    "for i in range(len(models)):\n",
    "\n",
    "    # create a pipeline\n",
    "    steps = [('t1', MinMaxScaler()), ('t2', PowerTransformer()),('m',models[i])]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    # evaluate the model and store results\n",
    "    scores = evaluate_model(X, y, pipeline)\n",
    "    results.append(scores)\n",
    "\n",
    "    # summarize and store\n",
    "    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))\n",
    "\n",
    "# plot the results\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, i can see a further lift in model skill for the three models that were evaluated.\n",
    "i can see that the LR appears to have out-performed the other two methods.\n",
    "\n",
    "Box and whisker plots are created for the results from each algorithm, suggesting perhaps\n",
    "a smaller and more focused spread for LR compared to the LDA, which was the second-best\n",
    "performing method. All methods still show skill on average, however the distribution of scores\n",
    "show runs that drop below 0.0 (no skill) in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction on New Data\n",
    "I will select the Logistic Regression model with a power transform on the input data as our\n",
    "final model. We can define and fit this model on the entire training dataset.\n",
    "i can use the fit model to make some predictions of probability for a\n",
    "few cases where we know there is survival and a few where we know there is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Cases:\n",
      ">data=[31, 59, 2], Survival=83.597%\n",
      ">data=[31, 65, 4], Survival=77.264%\n",
      ">data=[34, 60, 1], Survival=86.776%\n",
      "Non-Survival Cases:\n",
      ">data=[44, 64, 6], Survival=63.092%\n",
      ">data=[34, 66, 9], Survival=63.452%\n",
      ">data=[38, 69, 21], Survival=53.389%\n"
     ]
    }
   ],
   "source": [
    "# fit a model and make predictions for the haberman dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(full_path):\n",
    "\n",
    "    # load the dataset as a numpy array\n",
    "    data = read_csv(full_path, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = data.values\n",
    "\n",
    "    #split into input and output elements\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# fit the model\n",
    "steps = [('t1', MinMaxScaler()),('t2', PowerTransformer()),('m',LogisticRegression(solver='lbfgs'))]\n",
    "model = Pipeline(steps=steps)\n",
    "model.fit(X, y)\n",
    "\n",
    "# some survival cases\n",
    "print('Survival Cases:')\n",
    "data = [[31,59,2], [31,65,4], [34,60,1]]\n",
    "\n",
    "\n",
    "for row in data:\n",
    "    # make prediction\n",
    "    yhat = model.predict_proba([row])\n",
    "\n",
    "    # get percentage of survival\n",
    "    p_survive = yhat[0, 0] * 100\n",
    "\n",
    "    # summarize\n",
    "    print('>data=%s, Survival=%.3f%%' % (row, p_survive))\n",
    "\n",
    "\n",
    "print('Non-Survival Cases:')\n",
    "data = [[44,64,6], [34,66,9], [38,69,21]]\n",
    "for row in data:\n",
    "    # make prediction\n",
    "    yhat = model.predict_proba([row])\n",
    "\n",
    "    # get percentage of survival\n",
    "    p_survive = yhat[0, 0] * 100\n",
    "\n",
    "    # summarize\n",
    "    print('>data=%s, Survival=%.3f%%' % (row, p_survive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0af3aa2466c33c6431bfb6d8de92908ba4694b04397b92dd94bf4bb90d229b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
